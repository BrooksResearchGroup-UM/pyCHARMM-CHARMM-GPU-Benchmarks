# pyCHARMM/CHARMM GPU Benchmarks
## This repository contains benchmarks for the CHARMM/pyCHARMM program for computations run on current GPU platforms. These include the standard JAC/DHFR, ApoA1, DMPG and STMV benchmarks, ranging in system size from ~23K atoms to ~1M atoms. In addition, new benchmarks illustrate the application of $MS\lambda D$ for both protein (T4 Lysoyme) and ligand (HSP90) relative free energy (RFE) calculations. The ApoA1, DMPG and STMV, as well as the two $MS\lambda D$ benchmarks have been updated to utilize the recent CHARMM 36 parameter sets. The JAC/DHFR benchmark is adapted from the early benchmark developed by Brooks and Case for CHARMM and Amber. 
## The benchmarks are all run from a single Python script at the top level of this repository, `benchmark.py`, and this set-up is mirrored in the Jupyter notebook `benchmark.ipynb`. An additional Jupyter notebook that can be utilized to plot the collected benchmarks resides in `plot_benchmarks.ipynb`.
## The benchmarks were largely run on hardware present in the Brooks lab at the University of Michigan, with exception of the data for the *RTX 4090*, *RTX 3080* and *RTX 3080 TI* which were generated by Parveen Gartan from Bergen University, Norway, on local hardware accessible to him.
## All benchmarks were run in replicate to provide statistical variance of the resulting numbers through a `slurm` queueing system and simple `slurm` job files are contained.
# pyCHARMM/OpenMM Api achieves better than $2\ \mu\ sec/day$ on DHFR/JAC bechmark.
> ## DHFR/JAC benchmark - hydrogen mass repartitioning (HMR), 4 fs, NPT
<figure>
    <img src="figures/dhfr_page.pdf" alt="This is an alt">
    <figcaption>This is a caption</figcaption>
</figure>
